/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../mock-server/MockServerPool.js";
import { VapiClient } from "../../src/Client";

describe("Workflow", () => {
    test("WorkflowController_findAll", async () => {
        const server = mockServerPool.createServer();
        const client = new VapiClient({ token: "test", environment: server.baseUrl });

        const rawResponseBody = [
            {
                nodes: [
                    {
                        type: "conversation",
                        voice: {
                            cachingEnabled: true,
                            provider: "azure",
                            voiceId: "andrew",
                            fallbackPlan: { voices: [{ cachingEnabled: true, provider: "azure", voiceId: "andrew" }] },
                        },
                        name: "name",
                    },
                ],
                transcriber: {
                    provider: "assembly-ai",
                    language: "en",
                    confidenceThreshold: 0.4,
                    enableUniversalStreamingApi: false,
                    formatTurns: false,
                    endOfTurnConfidenceThreshold: 0.7,
                    minEndOfTurnSilenceWhenConfident: 160,
                    wordFinalizationMaxWaitTime: 160,
                    maxTurnSilence: 400,
                    realtimeUrl: "realtimeUrl",
                    wordBoost: ["wordBoost"],
                    endUtteranceSilenceThreshold: 1.1,
                    disablePartialTranscripts: true,
                    fallbackPlan: {
                        transcribers: [
                            {
                                provider: "assembly-ai",
                                confidenceThreshold: 0.4,
                                enableUniversalStreamingApi: false,
                                formatTurns: false,
                                endOfTurnConfidenceThreshold: 0.7,
                                minEndOfTurnSilenceWhenConfident: 160,
                                wordFinalizationMaxWaitTime: 160,
                                maxTurnSilence: 400,
                            },
                        ],
                    },
                },
                voice: {
                    cachingEnabled: true,
                    provider: "azure",
                    voiceId: "andrew",
                    chunkPlan: { enabled: true, minCharacters: 30 },
                    speed: 1.1,
                    fallbackPlan: { voices: [{ cachingEnabled: true, provider: "azure", voiceId: "andrew" }] },
                },
                observabilityPlan: { provider: "langfuse", tags: ["tags"], metadata: { key: "value" } },
                backgroundSound: "off",
                credentials: [{ provider: "11labs", apiKey: "apiKey" }],
                id: "id",
                orgId: "orgId",
                createdAt: "2024-01-15T09:30:00Z",
                updatedAt: "2024-01-15T09:30:00Z",
                name: "name",
                edges: [{ from: "from", to: "to" }],
                globalPrompt: "globalPrompt",
                server: {
                    timeoutSeconds: 20,
                    url: "url",
                    headers: { key: "value" },
                    backoffPlan: { type: { key: "value" }, maxRetries: 0, baseDelaySeconds: 1 },
                },
                compliancePlan: { hipaaEnabled: true, pciEnabled: true },
                analysisPlan: { minMessagesThreshold: 1.1, structuredDataMultiPlan: [{ key: "key", plan: {} }] },
                artifactPlan: {
                    recordingEnabled: true,
                    recordingFormat: "wav;l16",
                    videoRecordingEnabled: false,
                    pcapEnabled: true,
                    pcapS3PathPrefix: "/pcaps",
                    transcriptPlan: { enabled: true },
                    recordingPath: "recordingPath",
                },
                startSpeakingPlan: {
                    waitSeconds: 0.4,
                    smartEndpointingPlan: { provider: "vapi" },
                    customEndpointingRules: [{ type: "assistant", regex: "regex", timeoutSeconds: 1.1 }],
                    transcriptionEndpointingPlan: {
                        onPunctuationSeconds: 0.1,
                        onNoPunctuationSeconds: 1.5,
                        onNumberSeconds: 0.5,
                    },
                },
                stopSpeakingPlan: {
                    numWords: 0,
                    voiceSeconds: 0.2,
                    backoffSeconds: 1,
                    acknowledgementPhrases: [
                        "i understand",
                        "i see",
                        "i got it",
                        "i hear you",
                        "im listening",
                        "im with you",
                        "right",
                        "okay",
                        "ok",
                        "sure",
                        "alright",
                        "got it",
                        "understood",
                        "yeah",
                        "yes",
                        "uh-huh",
                        "mm-hmm",
                        "gotcha",
                        "mhmm",
                        "ah",
                        "yeah okay",
                        "yeah sure",
                    ],
                    interruptionPhrases: [
                        "stop",
                        "shut",
                        "up",
                        "enough",
                        "quiet",
                        "silence",
                        "but",
                        "dont",
                        "not",
                        "no",
                        "hold",
                        "wait",
                        "cut",
                        "pause",
                        "nope",
                        "nah",
                        "nevermind",
                        "never",
                        "bad",
                        "actually",
                    ],
                },
                monitorPlan: {
                    listenEnabled: false,
                    listenAuthenticationEnabled: false,
                    controlEnabled: false,
                    controlAuthenticationEnabled: false,
                },
                backgroundSpeechDenoisingPlan: {
                    fourierDenoisingPlan: {
                        mediaDetectionEnabled: true,
                        staticThreshold: -35,
                        baselineOffsetDb: -15,
                        windowSizeMs: 3000,
                        baselinePercentile: 85,
                    },
                },
                credentialIds: ["credentialIds"],
            },
        ];
        server.mockEndpoint().get("/workflow").respondWith().statusCode(200).jsonBody(rawResponseBody).build();

        const response = await client.workflow.workflowControllerFindAll();
        expect(response).toEqual([
            {
                nodes: [
                    {
                        type: "conversation",
                        voice: {
                            cachingEnabled: true,
                            provider: "azure",
                            voiceId: "andrew",
                            fallbackPlan: {
                                voices: [
                                    {
                                        cachingEnabled: true,
                                        provider: "azure",
                                        voiceId: "andrew",
                                    },
                                ],
                            },
                        },
                        name: "name",
                    },
                ],
                transcriber: {
                    provider: "assembly-ai",
                    language: "en",
                    confidenceThreshold: 0.4,
                    enableUniversalStreamingApi: false,
                    formatTurns: false,
                    endOfTurnConfidenceThreshold: 0.7,
                    minEndOfTurnSilenceWhenConfident: 160,
                    wordFinalizationMaxWaitTime: 160,
                    maxTurnSilence: 400,
                    realtimeUrl: "realtimeUrl",
                    wordBoost: ["wordBoost"],
                    endUtteranceSilenceThreshold: 1.1,
                    disablePartialTranscripts: true,
                    fallbackPlan: {
                        transcribers: [
                            {
                                provider: "assembly-ai",
                                confidenceThreshold: 0.4,
                                enableUniversalStreamingApi: false,
                                formatTurns: false,
                                endOfTurnConfidenceThreshold: 0.7,
                                minEndOfTurnSilenceWhenConfident: 160,
                                wordFinalizationMaxWaitTime: 160,
                                maxTurnSilence: 400,
                            },
                        ],
                    },
                },
                voice: {
                    cachingEnabled: true,
                    provider: "azure",
                    voiceId: "andrew",
                    chunkPlan: {
                        enabled: true,
                        minCharacters: 30,
                    },
                    speed: 1.1,
                    fallbackPlan: {
                        voices: [
                            {
                                cachingEnabled: true,
                                provider: "azure",
                                voiceId: "andrew",
                            },
                        ],
                    },
                },
                observabilityPlan: {
                    provider: "langfuse",
                    tags: ["tags"],
                    metadata: {
                        key: "value",
                    },
                },
                backgroundSound: "off",
                credentials: [
                    {
                        provider: "11labs",
                        apiKey: "apiKey",
                    },
                ],
                id: "id",
                orgId: "orgId",
                createdAt: "2024-01-15T09:30:00Z",
                updatedAt: "2024-01-15T09:30:00Z",
                name: "name",
                edges: [
                    {
                        from: "from",
                        to: "to",
                    },
                ],
                globalPrompt: "globalPrompt",
                server: {
                    timeoutSeconds: 20,
                    url: "url",
                    headers: {
                        key: "value",
                    },
                    backoffPlan: {
                        type: {
                            key: "value",
                        },
                        maxRetries: 0,
                        baseDelaySeconds: 1,
                    },
                },
                compliancePlan: {
                    hipaaEnabled: true,
                    pciEnabled: true,
                },
                analysisPlan: {
                    minMessagesThreshold: 1.1,
                    structuredDataMultiPlan: [
                        {
                            key: "key",
                            plan: {},
                        },
                    ],
                },
                artifactPlan: {
                    recordingEnabled: true,
                    recordingFormat: "wav;l16",
                    videoRecordingEnabled: false,
                    pcapEnabled: true,
                    pcapS3PathPrefix: "/pcaps",
                    transcriptPlan: {
                        enabled: true,
                    },
                    recordingPath: "recordingPath",
                },
                startSpeakingPlan: {
                    waitSeconds: 0.4,
                    smartEndpointingPlan: {
                        provider: "vapi",
                    },
                    customEndpointingRules: [
                        {
                            type: "assistant",
                            regex: "regex",
                            timeoutSeconds: 1.1,
                        },
                    ],
                    transcriptionEndpointingPlan: {
                        onPunctuationSeconds: 0.1,
                        onNoPunctuationSeconds: 1.5,
                        onNumberSeconds: 0.5,
                    },
                },
                stopSpeakingPlan: {
                    numWords: 0,
                    voiceSeconds: 0.2,
                    backoffSeconds: 1,
                    acknowledgementPhrases: [
                        "i understand",
                        "i see",
                        "i got it",
                        "i hear you",
                        "im listening",
                        "im with you",
                        "right",
                        "okay",
                        "ok",
                        "sure",
                        "alright",
                        "got it",
                        "understood",
                        "yeah",
                        "yes",
                        "uh-huh",
                        "mm-hmm",
                        "gotcha",
                        "mhmm",
                        "ah",
                        "yeah okay",
                        "yeah sure",
                    ],
                    interruptionPhrases: [
                        "stop",
                        "shut",
                        "up",
                        "enough",
                        "quiet",
                        "silence",
                        "but",
                        "dont",
                        "not",
                        "no",
                        "hold",
                        "wait",
                        "cut",
                        "pause",
                        "nope",
                        "nah",
                        "nevermind",
                        "never",
                        "bad",
                        "actually",
                    ],
                },
                monitorPlan: {
                    listenEnabled: false,
                    listenAuthenticationEnabled: false,
                    controlEnabled: false,
                    controlAuthenticationEnabled: false,
                },
                backgroundSpeechDenoisingPlan: {
                    fourierDenoisingPlan: {
                        mediaDetectionEnabled: true,
                        staticThreshold: -35,
                        baselineOffsetDb: -15,
                        windowSizeMs: 3000,
                        baselinePercentile: 85,
                    },
                },
                credentialIds: ["credentialIds"],
            },
        ]);
    });

    test("WorkflowController_create", async () => {
        const server = mockServerPool.createServer();
        const client = new VapiClient({ token: "test", environment: server.baseUrl });
        const rawRequestBody = {
            nodes: [{ type: "conversation", name: "name" }],
            name: "name",
            edges: [{ from: "from", to: "to" }],
        };
        const rawResponseBody = {
            nodes: [
                {
                    type: "conversation",
                    model: { provider: "openai", model: "gpt-4.1-2025-04-14" },
                    transcriber: {
                        provider: "assembly-ai",
                        confidenceThreshold: 0.4,
                        enableUniversalStreamingApi: false,
                        formatTurns: false,
                        endOfTurnConfidenceThreshold: 0.7,
                        minEndOfTurnSilenceWhenConfident: 160,
                        wordFinalizationMaxWaitTime: 160,
                        maxTurnSilence: 400,
                    },
                    voice: {
                        cachingEnabled: true,
                        provider: "azure",
                        voiceId: "andrew",
                        fallbackPlan: { voices: [{ cachingEnabled: true, provider: "azure", voiceId: "andrew" }] },
                    },
                    prompt: "prompt",
                    name: "name",
                    isStart: true,
                    metadata: { key: "value" },
                },
            ],
            transcriber: {
                provider: "assembly-ai",
                language: "en",
                confidenceThreshold: 0.4,
                enableUniversalStreamingApi: false,
                formatTurns: false,
                endOfTurnConfidenceThreshold: 0.7,
                minEndOfTurnSilenceWhenConfident: 160,
                wordFinalizationMaxWaitTime: 160,
                maxTurnSilence: 400,
                realtimeUrl: "realtimeUrl",
                wordBoost: ["wordBoost"],
                endUtteranceSilenceThreshold: 1.1,
                disablePartialTranscripts: true,
                fallbackPlan: {
                    transcribers: [
                        {
                            provider: "assembly-ai",
                            confidenceThreshold: 0.4,
                            enableUniversalStreamingApi: false,
                            formatTurns: false,
                            endOfTurnConfidenceThreshold: 0.7,
                            minEndOfTurnSilenceWhenConfident: 160,
                            wordFinalizationMaxWaitTime: 160,
                            maxTurnSilence: 400,
                        },
                    ],
                },
            },
            voice: {
                cachingEnabled: true,
                provider: "azure",
                voiceId: "andrew",
                chunkPlan: {
                    enabled: true,
                    minCharacters: 30,
                    punctuationBoundaries: ["。", "，", ".", "!", "?", ";", "،", "۔", "।", "॥", "|", "||", ",", ":"],
                    formatPlan: { enabled: true, numberToDigitsCutoff: 2025 },
                },
                speed: 1.1,
                fallbackPlan: { voices: [{ cachingEnabled: true, provider: "azure", voiceId: "andrew" }] },
            },
            observabilityPlan: { provider: "langfuse", tags: ["tags"], metadata: { key: "value" } },
            backgroundSound: "off",
            credentials: [{ provider: "11labs", apiKey: "apiKey", name: "name" }],
            id: "id",
            orgId: "orgId",
            createdAt: "2024-01-15T09:30:00Z",
            updatedAt: "2024-01-15T09:30:00Z",
            name: "name",
            edges: [
                { condition: { type: "ai", prompt: "prompt" }, from: "from", to: "to", metadata: { key: "value" } },
            ],
            globalPrompt: "globalPrompt",
            server: {
                timeoutSeconds: 20,
                url: "url",
                headers: { key: "value" },
                backoffPlan: { type: { key: "value" }, maxRetries: 0, baseDelaySeconds: 1 },
            },
            compliancePlan: { hipaaEnabled: true, pciEnabled: true },
            analysisPlan: {
                minMessagesThreshold: 1.1,
                summaryPlan: { messages: [{ key: "value" }], enabled: true, timeoutSeconds: 1.1 },
                structuredDataPlan: {
                    messages: [{ key: "value" }],
                    enabled: true,
                    schema: { type: "string" },
                    timeoutSeconds: 1.1,
                },
                structuredDataMultiPlan: [{ key: "key", plan: {} }],
                successEvaluationPlan: {
                    rubric: "NumericScale",
                    messages: [{ key: "value" }],
                    enabled: true,
                    timeoutSeconds: 1.1,
                },
            },
            artifactPlan: {
                recordingEnabled: true,
                recordingFormat: "wav;l16",
                videoRecordingEnabled: false,
                pcapEnabled: true,
                pcapS3PathPrefix: "/pcaps",
                transcriptPlan: { enabled: true, assistantName: "assistantName", userName: "userName" },
                recordingPath: "recordingPath",
            },
            startSpeakingPlan: {
                waitSeconds: 0.4,
                smartEndpointingPlan: { provider: "vapi" },
                customEndpointingRules: [{ type: "assistant", regex: "regex", timeoutSeconds: 1.1 }],
                transcriptionEndpointingPlan: {
                    onPunctuationSeconds: 0.1,
                    onNoPunctuationSeconds: 1.5,
                    onNumberSeconds: 0.5,
                },
            },
            stopSpeakingPlan: {
                numWords: 0,
                voiceSeconds: 0.2,
                backoffSeconds: 1,
                acknowledgementPhrases: [
                    "i understand",
                    "i see",
                    "i got it",
                    "i hear you",
                    "im listening",
                    "im with you",
                    "right",
                    "okay",
                    "ok",
                    "sure",
                    "alright",
                    "got it",
                    "understood",
                    "yeah",
                    "yes",
                    "uh-huh",
                    "mm-hmm",
                    "gotcha",
                    "mhmm",
                    "ah",
                    "yeah okay",
                    "yeah sure",
                ],
                interruptionPhrases: [
                    "stop",
                    "shut",
                    "up",
                    "enough",
                    "quiet",
                    "silence",
                    "but",
                    "dont",
                    "not",
                    "no",
                    "hold",
                    "wait",
                    "cut",
                    "pause",
                    "nope",
                    "nah",
                    "nevermind",
                    "never",
                    "bad",
                    "actually",
                ],
            },
            monitorPlan: {
                listenEnabled: false,
                listenAuthenticationEnabled: false,
                controlEnabled: false,
                controlAuthenticationEnabled: false,
            },
            backgroundSpeechDenoisingPlan: {
                smartDenoisingPlan: { enabled: true },
                fourierDenoisingPlan: {
                    enabled: true,
                    mediaDetectionEnabled: true,
                    staticThreshold: -35,
                    baselineOffsetDb: -15,
                    windowSizeMs: 3000,
                    baselinePercentile: 85,
                },
            },
            credentialIds: ["credentialIds"],
        };
        server
            .mockEndpoint()
            .post("/workflow")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.workflow.workflowControllerCreate({
            nodes: [
                {
                    type: "conversation",
                    name: "name",
                },
            ],
            name: "name",
            edges: [
                {
                    from: "from",
                    to: "to",
                },
            ],
        });
        expect(response).toEqual({
            nodes: [
                {
                    type: "conversation",
                    model: {
                        provider: "openai",
                        model: "gpt-4.1-2025-04-14",
                    },
                    transcriber: {
                        provider: "assembly-ai",
                        confidenceThreshold: 0.4,
                        enableUniversalStreamingApi: false,
                        formatTurns: false,
                        endOfTurnConfidenceThreshold: 0.7,
                        minEndOfTurnSilenceWhenConfident: 160,
                        wordFinalizationMaxWaitTime: 160,
                        maxTurnSilence: 400,
                    },
                    voice: {
                        cachingEnabled: true,
                        provider: "azure",
                        voiceId: "andrew",
                        fallbackPlan: {
                            voices: [
                                {
                                    cachingEnabled: true,
                                    provider: "azure",
                                    voiceId: "andrew",
                                },
                            ],
                        },
                    },
                    prompt: "prompt",
                    name: "name",
                    isStart: true,
                    metadata: {
                        key: "value",
                    },
                },
            ],
            transcriber: {
                provider: "assembly-ai",
                language: "en",
                confidenceThreshold: 0.4,
                enableUniversalStreamingApi: false,
                formatTurns: false,
                endOfTurnConfidenceThreshold: 0.7,
                minEndOfTurnSilenceWhenConfident: 160,
                wordFinalizationMaxWaitTime: 160,
                maxTurnSilence: 400,
                realtimeUrl: "realtimeUrl",
                wordBoost: ["wordBoost"],
                endUtteranceSilenceThreshold: 1.1,
                disablePartialTranscripts: true,
                fallbackPlan: {
                    transcribers: [
                        {
                            provider: "assembly-ai",
                            confidenceThreshold: 0.4,
                            enableUniversalStreamingApi: false,
                            formatTurns: false,
                            endOfTurnConfidenceThreshold: 0.7,
                            minEndOfTurnSilenceWhenConfident: 160,
                            wordFinalizationMaxWaitTime: 160,
                            maxTurnSilence: 400,
                        },
                    ],
                },
            },
            voice: {
                cachingEnabled: true,
                provider: "azure",
                voiceId: "andrew",
                chunkPlan: {
                    enabled: true,
                    minCharacters: 30,
                    punctuationBoundaries: [
                        "\u3002",
                        "\uFF0C",
                        ".",
                        "!",
                        "?",
                        ";",
                        "\u060C",
                        "\u06D4",
                        "\u0964",
                        "\u0965",
                        "|",
                        "||",
                        ",",
                        ":",
                    ],
                    formatPlan: {
                        enabled: true,
                        numberToDigitsCutoff: 2025,
                    },
                },
                speed: 1.1,
                fallbackPlan: {
                    voices: [
                        {
                            cachingEnabled: true,
                            provider: "azure",
                            voiceId: "andrew",
                        },
                    ],
                },
            },
            observabilityPlan: {
                provider: "langfuse",
                tags: ["tags"],
                metadata: {
                    key: "value",
                },
            },
            backgroundSound: "off",
            credentials: [
                {
                    provider: "11labs",
                    apiKey: "apiKey",
                    name: "name",
                },
            ],
            id: "id",
            orgId: "orgId",
            createdAt: "2024-01-15T09:30:00Z",
            updatedAt: "2024-01-15T09:30:00Z",
            name: "name",
            edges: [
                {
                    condition: {
                        type: "ai",
                        prompt: "prompt",
                    },
                    from: "from",
                    to: "to",
                    metadata: {
                        key: "value",
                    },
                },
            ],
            globalPrompt: "globalPrompt",
            server: {
                timeoutSeconds: 20,
                url: "url",
                headers: {
                    key: "value",
                },
                backoffPlan: {
                    type: {
                        key: "value",
                    },
                    maxRetries: 0,
                    baseDelaySeconds: 1,
                },
            },
            compliancePlan: {
                hipaaEnabled: true,
                pciEnabled: true,
            },
            analysisPlan: {
                minMessagesThreshold: 1.1,
                summaryPlan: {
                    messages: [
                        {
                            key: "value",
                        },
                    ],
                    enabled: true,
                    timeoutSeconds: 1.1,
                },
                structuredDataPlan: {
                    messages: [
                        {
                            key: "value",
                        },
                    ],
                    enabled: true,
                    schema: {
                        type: "string",
                    },
                    timeoutSeconds: 1.1,
                },
                structuredDataMultiPlan: [
                    {
                        key: "key",
                        plan: {},
                    },
                ],
                successEvaluationPlan: {
                    rubric: "NumericScale",
                    messages: [
                        {
                            key: "value",
                        },
                    ],
                    enabled: true,
                    timeoutSeconds: 1.1,
                },
            },
            artifactPlan: {
                recordingEnabled: true,
                recordingFormat: "wav;l16",
                videoRecordingEnabled: false,
                pcapEnabled: true,
                pcapS3PathPrefix: "/pcaps",
                transcriptPlan: {
                    enabled: true,
                    assistantName: "assistantName",
                    userName: "userName",
                },
                recordingPath: "recordingPath",
            },
            startSpeakingPlan: {
                waitSeconds: 0.4,
                smartEndpointingPlan: {
                    provider: "vapi",
                },
                customEndpointingRules: [
                    {
                        type: "assistant",
                        regex: "regex",
                        timeoutSeconds: 1.1,
                    },
                ],
                transcriptionEndpointingPlan: {
                    onPunctuationSeconds: 0.1,
                    onNoPunctuationSeconds: 1.5,
                    onNumberSeconds: 0.5,
                },
            },
            stopSpeakingPlan: {
                numWords: 0,
                voiceSeconds: 0.2,
                backoffSeconds: 1,
                acknowledgementPhrases: [
                    "i understand",
                    "i see",
                    "i got it",
                    "i hear you",
                    "im listening",
                    "im with you",
                    "right",
                    "okay",
                    "ok",
                    "sure",
                    "alright",
                    "got it",
                    "understood",
                    "yeah",
                    "yes",
                    "uh-huh",
                    "mm-hmm",
                    "gotcha",
                    "mhmm",
                    "ah",
                    "yeah okay",
                    "yeah sure",
                ],
                interruptionPhrases: [
                    "stop",
                    "shut",
                    "up",
                    "enough",
                    "quiet",
                    "silence",
                    "but",
                    "dont",
                    "not",
                    "no",
                    "hold",
                    "wait",
                    "cut",
                    "pause",
                    "nope",
                    "nah",
                    "nevermind",
                    "never",
                    "bad",
                    "actually",
                ],
            },
            monitorPlan: {
                listenEnabled: false,
                listenAuthenticationEnabled: false,
                controlEnabled: false,
                controlAuthenticationEnabled: false,
            },
            backgroundSpeechDenoisingPlan: {
                smartDenoisingPlan: {
                    enabled: true,
                },
                fourierDenoisingPlan: {
                    enabled: true,
                    mediaDetectionEnabled: true,
                    staticThreshold: -35,
                    baselineOffsetDb: -15,
                    windowSizeMs: 3000,
                    baselinePercentile: 85,
                },
            },
            credentialIds: ["credentialIds"],
        });
    });

    test("WorkflowController_findOne", async () => {
        const server = mockServerPool.createServer();
        const client = new VapiClient({ token: "test", environment: server.baseUrl });

        const rawResponseBody = {
            nodes: [
                {
                    type: "conversation",
                    model: { provider: "openai", model: "gpt-4.1-2025-04-14" },
                    transcriber: {
                        provider: "assembly-ai",
                        confidenceThreshold: 0.4,
                        enableUniversalStreamingApi: false,
                        formatTurns: false,
                        endOfTurnConfidenceThreshold: 0.7,
                        minEndOfTurnSilenceWhenConfident: 160,
                        wordFinalizationMaxWaitTime: 160,
                        maxTurnSilence: 400,
                    },
                    voice: {
                        cachingEnabled: true,
                        provider: "azure",
                        voiceId: "andrew",
                        fallbackPlan: { voices: [{ cachingEnabled: true, provider: "azure", voiceId: "andrew" }] },
                    },
                    prompt: "prompt",
                    name: "name",
                    isStart: true,
                    metadata: { key: "value" },
                },
            ],
            transcriber: {
                provider: "assembly-ai",
                language: "en",
                confidenceThreshold: 0.4,
                enableUniversalStreamingApi: false,
                formatTurns: false,
                endOfTurnConfidenceThreshold: 0.7,
                minEndOfTurnSilenceWhenConfident: 160,
                wordFinalizationMaxWaitTime: 160,
                maxTurnSilence: 400,
                realtimeUrl: "realtimeUrl",
                wordBoost: ["wordBoost"],
                endUtteranceSilenceThreshold: 1.1,
                disablePartialTranscripts: true,
                fallbackPlan: {
                    transcribers: [
                        {
                            provider: "assembly-ai",
                            confidenceThreshold: 0.4,
                            enableUniversalStreamingApi: false,
                            formatTurns: false,
                            endOfTurnConfidenceThreshold: 0.7,
                            minEndOfTurnSilenceWhenConfident: 160,
                            wordFinalizationMaxWaitTime: 160,
                            maxTurnSilence: 400,
                        },
                    ],
                },
            },
            voice: {
                cachingEnabled: true,
                provider: "azure",
                voiceId: "andrew",
                chunkPlan: {
                    enabled: true,
                    minCharacters: 30,
                    punctuationBoundaries: ["。", "，", ".", "!", "?", ";", "،", "۔", "।", "॥", "|", "||", ",", ":"],
                    formatPlan: { enabled: true, numberToDigitsCutoff: 2025 },
                },
                speed: 1.1,
                fallbackPlan: { voices: [{ cachingEnabled: true, provider: "azure", voiceId: "andrew" }] },
            },
            observabilityPlan: { provider: "langfuse", tags: ["tags"], metadata: { key: "value" } },
            backgroundSound: "off",
            credentials: [{ provider: "11labs", apiKey: "apiKey", name: "name" }],
            id: "id",
            orgId: "orgId",
            createdAt: "2024-01-15T09:30:00Z",
            updatedAt: "2024-01-15T09:30:00Z",
            name: "name",
            edges: [
                { condition: { type: "ai", prompt: "prompt" }, from: "from", to: "to", metadata: { key: "value" } },
            ],
            globalPrompt: "globalPrompt",
            server: {
                timeoutSeconds: 20,
                url: "url",
                headers: { key: "value" },
                backoffPlan: { type: { key: "value" }, maxRetries: 0, baseDelaySeconds: 1 },
            },
            compliancePlan: { hipaaEnabled: true, pciEnabled: true },
            analysisPlan: {
                minMessagesThreshold: 1.1,
                summaryPlan: { messages: [{ key: "value" }], enabled: true, timeoutSeconds: 1.1 },
                structuredDataPlan: {
                    messages: [{ key: "value" }],
                    enabled: true,
                    schema: { type: "string" },
                    timeoutSeconds: 1.1,
                },
                structuredDataMultiPlan: [{ key: "key", plan: {} }],
                successEvaluationPlan: {
                    rubric: "NumericScale",
                    messages: [{ key: "value" }],
                    enabled: true,
                    timeoutSeconds: 1.1,
                },
            },
            artifactPlan: {
                recordingEnabled: true,
                recordingFormat: "wav;l16",
                videoRecordingEnabled: false,
                pcapEnabled: true,
                pcapS3PathPrefix: "/pcaps",
                transcriptPlan: { enabled: true, assistantName: "assistantName", userName: "userName" },
                recordingPath: "recordingPath",
            },
            startSpeakingPlan: {
                waitSeconds: 0.4,
                smartEndpointingPlan: { provider: "vapi" },
                customEndpointingRules: [{ type: "assistant", regex: "regex", timeoutSeconds: 1.1 }],
                transcriptionEndpointingPlan: {
                    onPunctuationSeconds: 0.1,
                    onNoPunctuationSeconds: 1.5,
                    onNumberSeconds: 0.5,
                },
            },
            stopSpeakingPlan: {
                numWords: 0,
                voiceSeconds: 0.2,
                backoffSeconds: 1,
                acknowledgementPhrases: [
                    "i understand",
                    "i see",
                    "i got it",
                    "i hear you",
                    "im listening",
                    "im with you",
                    "right",
                    "okay",
                    "ok",
                    "sure",
                    "alright",
                    "got it",
                    "understood",
                    "yeah",
                    "yes",
                    "uh-huh",
                    "mm-hmm",
                    "gotcha",
                    "mhmm",
                    "ah",
                    "yeah okay",
                    "yeah sure",
                ],
                interruptionPhrases: [
                    "stop",
                    "shut",
                    "up",
                    "enough",
                    "quiet",
                    "silence",
                    "but",
                    "dont",
                    "not",
                    "no",
                    "hold",
                    "wait",
                    "cut",
                    "pause",
                    "nope",
                    "nah",
                    "nevermind",
                    "never",
                    "bad",
                    "actually",
                ],
            },
            monitorPlan: {
                listenEnabled: false,
                listenAuthenticationEnabled: false,
                controlEnabled: false,
                controlAuthenticationEnabled: false,
            },
            backgroundSpeechDenoisingPlan: {
                smartDenoisingPlan: { enabled: true },
                fourierDenoisingPlan: {
                    enabled: true,
                    mediaDetectionEnabled: true,
                    staticThreshold: -35,
                    baselineOffsetDb: -15,
                    windowSizeMs: 3000,
                    baselinePercentile: 85,
                },
            },
            credentialIds: ["credentialIds"],
        };
        server.mockEndpoint().get("/workflow/id").respondWith().statusCode(200).jsonBody(rawResponseBody).build();

        const response = await client.workflow.workflowControllerFindOne("id");
        expect(response).toEqual({
            nodes: [
                {
                    type: "conversation",
                    model: {
                        provider: "openai",
                        model: "gpt-4.1-2025-04-14",
                    },
                    transcriber: {
                        provider: "assembly-ai",
                        confidenceThreshold: 0.4,
                        enableUniversalStreamingApi: false,
                        formatTurns: false,
                        endOfTurnConfidenceThreshold: 0.7,
                        minEndOfTurnSilenceWhenConfident: 160,
                        wordFinalizationMaxWaitTime: 160,
                        maxTurnSilence: 400,
                    },
                    voice: {
                        cachingEnabled: true,
                        provider: "azure",
                        voiceId: "andrew",
                        fallbackPlan: {
                            voices: [
                                {
                                    cachingEnabled: true,
                                    provider: "azure",
                                    voiceId: "andrew",
                                },
                            ],
                        },
                    },
                    prompt: "prompt",
                    name: "name",
                    isStart: true,
                    metadata: {
                        key: "value",
                    },
                },
            ],
            transcriber: {
                provider: "assembly-ai",
                language: "en",
                confidenceThreshold: 0.4,
                enableUniversalStreamingApi: false,
                formatTurns: false,
                endOfTurnConfidenceThreshold: 0.7,
                minEndOfTurnSilenceWhenConfident: 160,
                wordFinalizationMaxWaitTime: 160,
                maxTurnSilence: 400,
                realtimeUrl: "realtimeUrl",
                wordBoost: ["wordBoost"],
                endUtteranceSilenceThreshold: 1.1,
                disablePartialTranscripts: true,
                fallbackPlan: {
                    transcribers: [
                        {
                            provider: "assembly-ai",
                            confidenceThreshold: 0.4,
                            enableUniversalStreamingApi: false,
                            formatTurns: false,
                            endOfTurnConfidenceThreshold: 0.7,
                            minEndOfTurnSilenceWhenConfident: 160,
                            wordFinalizationMaxWaitTime: 160,
                            maxTurnSilence: 400,
                        },
                    ],
                },
            },
            voice: {
                cachingEnabled: true,
                provider: "azure",
                voiceId: "andrew",
                chunkPlan: {
                    enabled: true,
                    minCharacters: 30,
                    punctuationBoundaries: [
                        "\u3002",
                        "\uFF0C",
                        ".",
                        "!",
                        "?",
                        ";",
                        "\u060C",
                        "\u06D4",
                        "\u0964",
                        "\u0965",
                        "|",
                        "||",
                        ",",
                        ":",
                    ],
                    formatPlan: {
                        enabled: true,
                        numberToDigitsCutoff: 2025,
                    },
                },
                speed: 1.1,
                fallbackPlan: {
                    voices: [
                        {
                            cachingEnabled: true,
                            provider: "azure",
                            voiceId: "andrew",
                        },
                    ],
                },
            },
            observabilityPlan: {
                provider: "langfuse",
                tags: ["tags"],
                metadata: {
                    key: "value",
                },
            },
            backgroundSound: "off",
            credentials: [
                {
                    provider: "11labs",
                    apiKey: "apiKey",
                    name: "name",
                },
            ],
            id: "id",
            orgId: "orgId",
            createdAt: "2024-01-15T09:30:00Z",
            updatedAt: "2024-01-15T09:30:00Z",
            name: "name",
            edges: [
                {
                    condition: {
                        type: "ai",
                        prompt: "prompt",
                    },
                    from: "from",
                    to: "to",
                    metadata: {
                        key: "value",
                    },
                },
            ],
            globalPrompt: "globalPrompt",
            server: {
                timeoutSeconds: 20,
                url: "url",
                headers: {
                    key: "value",
                },
                backoffPlan: {
                    type: {
                        key: "value",
                    },
                    maxRetries: 0,
                    baseDelaySeconds: 1,
                },
            },
            compliancePlan: {
                hipaaEnabled: true,
                pciEnabled: true,
            },
            analysisPlan: {
                minMessagesThreshold: 1.1,
                summaryPlan: {
                    messages: [
                        {
                            key: "value",
                        },
                    ],
                    enabled: true,
                    timeoutSeconds: 1.1,
                },
                structuredDataPlan: {
                    messages: [
                        {
                            key: "value",
                        },
                    ],
                    enabled: true,
                    schema: {
                        type: "string",
                    },
                    timeoutSeconds: 1.1,
                },
                structuredDataMultiPlan: [
                    {
                        key: "key",
                        plan: {},
                    },
                ],
                successEvaluationPlan: {
                    rubric: "NumericScale",
                    messages: [
                        {
                            key: "value",
                        },
                    ],
                    enabled: true,
                    timeoutSeconds: 1.1,
                },
            },
            artifactPlan: {
                recordingEnabled: true,
                recordingFormat: "wav;l16",
                videoRecordingEnabled: false,
                pcapEnabled: true,
                pcapS3PathPrefix: "/pcaps",
                transcriptPlan: {
                    enabled: true,
                    assistantName: "assistantName",
                    userName: "userName",
                },
                recordingPath: "recordingPath",
            },
            startSpeakingPlan: {
                waitSeconds: 0.4,
                smartEndpointingPlan: {
                    provider: "vapi",
                },
                customEndpointingRules: [
                    {
                        type: "assistant",
                        regex: "regex",
                        timeoutSeconds: 1.1,
                    },
                ],
                transcriptionEndpointingPlan: {
                    onPunctuationSeconds: 0.1,
                    onNoPunctuationSeconds: 1.5,
                    onNumberSeconds: 0.5,
                },
            },
            stopSpeakingPlan: {
                numWords: 0,
                voiceSeconds: 0.2,
                backoffSeconds: 1,
                acknowledgementPhrases: [
                    "i understand",
                    "i see",
                    "i got it",
                    "i hear you",
                    "im listening",
                    "im with you",
                    "right",
                    "okay",
                    "ok",
                    "sure",
                    "alright",
                    "got it",
                    "understood",
                    "yeah",
                    "yes",
                    "uh-huh",
                    "mm-hmm",
                    "gotcha",
                    "mhmm",
                    "ah",
                    "yeah okay",
                    "yeah sure",
                ],
                interruptionPhrases: [
                    "stop",
                    "shut",
                    "up",
                    "enough",
                    "quiet",
                    "silence",
                    "but",
                    "dont",
                    "not",
                    "no",
                    "hold",
                    "wait",
                    "cut",
                    "pause",
                    "nope",
                    "nah",
                    "nevermind",
                    "never",
                    "bad",
                    "actually",
                ],
            },
            monitorPlan: {
                listenEnabled: false,
                listenAuthenticationEnabled: false,
                controlEnabled: false,
                controlAuthenticationEnabled: false,
            },
            backgroundSpeechDenoisingPlan: {
                smartDenoisingPlan: {
                    enabled: true,
                },
                fourierDenoisingPlan: {
                    enabled: true,
                    mediaDetectionEnabled: true,
                    staticThreshold: -35,
                    baselineOffsetDb: -15,
                    windowSizeMs: 3000,
                    baselinePercentile: 85,
                },
            },
            credentialIds: ["credentialIds"],
        });
    });

    test("WorkflowController_delete", async () => {
        const server = mockServerPool.createServer();
        const client = new VapiClient({ token: "test", environment: server.baseUrl });

        const rawResponseBody = {
            nodes: [
                {
                    type: "conversation",
                    model: { provider: "openai", model: "gpt-4.1-2025-04-14" },
                    transcriber: {
                        provider: "assembly-ai",
                        confidenceThreshold: 0.4,
                        enableUniversalStreamingApi: false,
                        formatTurns: false,
                        endOfTurnConfidenceThreshold: 0.7,
                        minEndOfTurnSilenceWhenConfident: 160,
                        wordFinalizationMaxWaitTime: 160,
                        maxTurnSilence: 400,
                    },
                    voice: {
                        cachingEnabled: true,
                        provider: "azure",
                        voiceId: "andrew",
                        fallbackPlan: { voices: [{ cachingEnabled: true, provider: "azure", voiceId: "andrew" }] },
                    },
                    prompt: "prompt",
                    name: "name",
                    isStart: true,
                    metadata: { key: "value" },
                },
            ],
            transcriber: {
                provider: "assembly-ai",
                language: "en",
                confidenceThreshold: 0.4,
                enableUniversalStreamingApi: false,
                formatTurns: false,
                endOfTurnConfidenceThreshold: 0.7,
                minEndOfTurnSilenceWhenConfident: 160,
                wordFinalizationMaxWaitTime: 160,
                maxTurnSilence: 400,
                realtimeUrl: "realtimeUrl",
                wordBoost: ["wordBoost"],
                endUtteranceSilenceThreshold: 1.1,
                disablePartialTranscripts: true,
                fallbackPlan: {
                    transcribers: [
                        {
                            provider: "assembly-ai",
                            confidenceThreshold: 0.4,
                            enableUniversalStreamingApi: false,
                            formatTurns: false,
                            endOfTurnConfidenceThreshold: 0.7,
                            minEndOfTurnSilenceWhenConfident: 160,
                            wordFinalizationMaxWaitTime: 160,
                            maxTurnSilence: 400,
                        },
                    ],
                },
            },
            voice: {
                cachingEnabled: true,
                provider: "azure",
                voiceId: "andrew",
                chunkPlan: {
                    enabled: true,
                    minCharacters: 30,
                    punctuationBoundaries: ["。", "，", ".", "!", "?", ";", "،", "۔", "।", "॥", "|", "||", ",", ":"],
                    formatPlan: { enabled: true, numberToDigitsCutoff: 2025 },
                },
                speed: 1.1,
                fallbackPlan: { voices: [{ cachingEnabled: true, provider: "azure", voiceId: "andrew" }] },
            },
            observabilityPlan: { provider: "langfuse", tags: ["tags"], metadata: { key: "value" } },
            backgroundSound: "off",
            credentials: [{ provider: "11labs", apiKey: "apiKey", name: "name" }],
            id: "id",
            orgId: "orgId",
            createdAt: "2024-01-15T09:30:00Z",
            updatedAt: "2024-01-15T09:30:00Z",
            name: "name",
            edges: [
                { condition: { type: "ai", prompt: "prompt" }, from: "from", to: "to", metadata: { key: "value" } },
            ],
            globalPrompt: "globalPrompt",
            server: {
                timeoutSeconds: 20,
                url: "url",
                headers: { key: "value" },
                backoffPlan: { type: { key: "value" }, maxRetries: 0, baseDelaySeconds: 1 },
            },
            compliancePlan: { hipaaEnabled: true, pciEnabled: true },
            analysisPlan: {
                minMessagesThreshold: 1.1,
                summaryPlan: { messages: [{ key: "value" }], enabled: true, timeoutSeconds: 1.1 },
                structuredDataPlan: {
                    messages: [{ key: "value" }],
                    enabled: true,
                    schema: { type: "string" },
                    timeoutSeconds: 1.1,
                },
                structuredDataMultiPlan: [{ key: "key", plan: {} }],
                successEvaluationPlan: {
                    rubric: "NumericScale",
                    messages: [{ key: "value" }],
                    enabled: true,
                    timeoutSeconds: 1.1,
                },
            },
            artifactPlan: {
                recordingEnabled: true,
                recordingFormat: "wav;l16",
                videoRecordingEnabled: false,
                pcapEnabled: true,
                pcapS3PathPrefix: "/pcaps",
                transcriptPlan: { enabled: true, assistantName: "assistantName", userName: "userName" },
                recordingPath: "recordingPath",
            },
            startSpeakingPlan: {
                waitSeconds: 0.4,
                smartEndpointingPlan: { provider: "vapi" },
                customEndpointingRules: [{ type: "assistant", regex: "regex", timeoutSeconds: 1.1 }],
                transcriptionEndpointingPlan: {
                    onPunctuationSeconds: 0.1,
                    onNoPunctuationSeconds: 1.5,
                    onNumberSeconds: 0.5,
                },
            },
            stopSpeakingPlan: {
                numWords: 0,
                voiceSeconds: 0.2,
                backoffSeconds: 1,
                acknowledgementPhrases: [
                    "i understand",
                    "i see",
                    "i got it",
                    "i hear you",
                    "im listening",
                    "im with you",
                    "right",
                    "okay",
                    "ok",
                    "sure",
                    "alright",
                    "got it",
                    "understood",
                    "yeah",
                    "yes",
                    "uh-huh",
                    "mm-hmm",
                    "gotcha",
                    "mhmm",
                    "ah",
                    "yeah okay",
                    "yeah sure",
                ],
                interruptionPhrases: [
                    "stop",
                    "shut",
                    "up",
                    "enough",
                    "quiet",
                    "silence",
                    "but",
                    "dont",
                    "not",
                    "no",
                    "hold",
                    "wait",
                    "cut",
                    "pause",
                    "nope",
                    "nah",
                    "nevermind",
                    "never",
                    "bad",
                    "actually",
                ],
            },
            monitorPlan: {
                listenEnabled: false,
                listenAuthenticationEnabled: false,
                controlEnabled: false,
                controlAuthenticationEnabled: false,
            },
            backgroundSpeechDenoisingPlan: {
                smartDenoisingPlan: { enabled: true },
                fourierDenoisingPlan: {
                    enabled: true,
                    mediaDetectionEnabled: true,
                    staticThreshold: -35,
                    baselineOffsetDb: -15,
                    windowSizeMs: 3000,
                    baselinePercentile: 85,
                },
            },
            credentialIds: ["credentialIds"],
        };
        server.mockEndpoint().delete("/workflow/id").respondWith().statusCode(200).jsonBody(rawResponseBody).build();

        const response = await client.workflow.workflowControllerDelete("id");
        expect(response).toEqual({
            nodes: [
                {
                    type: "conversation",
                    model: {
                        provider: "openai",
                        model: "gpt-4.1-2025-04-14",
                    },
                    transcriber: {
                        provider: "assembly-ai",
                        confidenceThreshold: 0.4,
                        enableUniversalStreamingApi: false,
                        formatTurns: false,
                        endOfTurnConfidenceThreshold: 0.7,
                        minEndOfTurnSilenceWhenConfident: 160,
                        wordFinalizationMaxWaitTime: 160,
                        maxTurnSilence: 400,
                    },
                    voice: {
                        cachingEnabled: true,
                        provider: "azure",
                        voiceId: "andrew",
                        fallbackPlan: {
                            voices: [
                                {
                                    cachingEnabled: true,
                                    provider: "azure",
                                    voiceId: "andrew",
                                },
                            ],
                        },
                    },
                    prompt: "prompt",
                    name: "name",
                    isStart: true,
                    metadata: {
                        key: "value",
                    },
                },
            ],
            transcriber: {
                provider: "assembly-ai",
                language: "en",
                confidenceThreshold: 0.4,
                enableUniversalStreamingApi: false,
                formatTurns: false,
                endOfTurnConfidenceThreshold: 0.7,
                minEndOfTurnSilenceWhenConfident: 160,
                wordFinalizationMaxWaitTime: 160,
                maxTurnSilence: 400,
                realtimeUrl: "realtimeUrl",
                wordBoost: ["wordBoost"],
                endUtteranceSilenceThreshold: 1.1,
                disablePartialTranscripts: true,
                fallbackPlan: {
                    transcribers: [
                        {
                            provider: "assembly-ai",
                            confidenceThreshold: 0.4,
                            enableUniversalStreamingApi: false,
                            formatTurns: false,
                            endOfTurnConfidenceThreshold: 0.7,
                            minEndOfTurnSilenceWhenConfident: 160,
                            wordFinalizationMaxWaitTime: 160,
                            maxTurnSilence: 400,
                        },
                    ],
                },
            },
            voice: {
                cachingEnabled: true,
                provider: "azure",
                voiceId: "andrew",
                chunkPlan: {
                    enabled: true,
                    minCharacters: 30,
                    punctuationBoundaries: [
                        "\u3002",
                        "\uFF0C",
                        ".",
                        "!",
                        "?",
                        ";",
                        "\u060C",
                        "\u06D4",
                        "\u0964",
                        "\u0965",
                        "|",
                        "||",
                        ",",
                        ":",
                    ],
                    formatPlan: {
                        enabled: true,
                        numberToDigitsCutoff: 2025,
                    },
                },
                speed: 1.1,
                fallbackPlan: {
                    voices: [
                        {
                            cachingEnabled: true,
                            provider: "azure",
                            voiceId: "andrew",
                        },
                    ],
                },
            },
            observabilityPlan: {
                provider: "langfuse",
                tags: ["tags"],
                metadata: {
                    key: "value",
                },
            },
            backgroundSound: "off",
            credentials: [
                {
                    provider: "11labs",
                    apiKey: "apiKey",
                    name: "name",
                },
            ],
            id: "id",
            orgId: "orgId",
            createdAt: "2024-01-15T09:30:00Z",
            updatedAt: "2024-01-15T09:30:00Z",
            name: "name",
            edges: [
                {
                    condition: {
                        type: "ai",
                        prompt: "prompt",
                    },
                    from: "from",
                    to: "to",
                    metadata: {
                        key: "value",
                    },
                },
            ],
            globalPrompt: "globalPrompt",
            server: {
                timeoutSeconds: 20,
                url: "url",
                headers: {
                    key: "value",
                },
                backoffPlan: {
                    type: {
                        key: "value",
                    },
                    maxRetries: 0,
                    baseDelaySeconds: 1,
                },
            },
            compliancePlan: {
                hipaaEnabled: true,
                pciEnabled: true,
            },
            analysisPlan: {
                minMessagesThreshold: 1.1,
                summaryPlan: {
                    messages: [
                        {
                            key: "value",
                        },
                    ],
                    enabled: true,
                    timeoutSeconds: 1.1,
                },
                structuredDataPlan: {
                    messages: [
                        {
                            key: "value",
                        },
                    ],
                    enabled: true,
                    schema: {
                        type: "string",
                    },
                    timeoutSeconds: 1.1,
                },
                structuredDataMultiPlan: [
                    {
                        key: "key",
                        plan: {},
                    },
                ],
                successEvaluationPlan: {
                    rubric: "NumericScale",
                    messages: [
                        {
                            key: "value",
                        },
                    ],
                    enabled: true,
                    timeoutSeconds: 1.1,
                },
            },
            artifactPlan: {
                recordingEnabled: true,
                recordingFormat: "wav;l16",
                videoRecordingEnabled: false,
                pcapEnabled: true,
                pcapS3PathPrefix: "/pcaps",
                transcriptPlan: {
                    enabled: true,
                    assistantName: "assistantName",
                    userName: "userName",
                },
                recordingPath: "recordingPath",
            },
            startSpeakingPlan: {
                waitSeconds: 0.4,
                smartEndpointingPlan: {
                    provider: "vapi",
                },
                customEndpointingRules: [
                    {
                        type: "assistant",
                        regex: "regex",
                        timeoutSeconds: 1.1,
                    },
                ],
                transcriptionEndpointingPlan: {
                    onPunctuationSeconds: 0.1,
                    onNoPunctuationSeconds: 1.5,
                    onNumberSeconds: 0.5,
                },
            },
            stopSpeakingPlan: {
                numWords: 0,
                voiceSeconds: 0.2,
                backoffSeconds: 1,
                acknowledgementPhrases: [
                    "i understand",
                    "i see",
                    "i got it",
                    "i hear you",
                    "im listening",
                    "im with you",
                    "right",
                    "okay",
                    "ok",
                    "sure",
                    "alright",
                    "got it",
                    "understood",
                    "yeah",
                    "yes",
                    "uh-huh",
                    "mm-hmm",
                    "gotcha",
                    "mhmm",
                    "ah",
                    "yeah okay",
                    "yeah sure",
                ],
                interruptionPhrases: [
                    "stop",
                    "shut",
                    "up",
                    "enough",
                    "quiet",
                    "silence",
                    "but",
                    "dont",
                    "not",
                    "no",
                    "hold",
                    "wait",
                    "cut",
                    "pause",
                    "nope",
                    "nah",
                    "nevermind",
                    "never",
                    "bad",
                    "actually",
                ],
            },
            monitorPlan: {
                listenEnabled: false,
                listenAuthenticationEnabled: false,
                controlEnabled: false,
                controlAuthenticationEnabled: false,
            },
            backgroundSpeechDenoisingPlan: {
                smartDenoisingPlan: {
                    enabled: true,
                },
                fourierDenoisingPlan: {
                    enabled: true,
                    mediaDetectionEnabled: true,
                    staticThreshold: -35,
                    baselineOffsetDb: -15,
                    windowSizeMs: 3000,
                    baselinePercentile: 85,
                },
            },
            credentialIds: ["credentialIds"],
        });
    });

    test("WorkflowController_update", async () => {
        const server = mockServerPool.createServer();
        const client = new VapiClient({ token: "test", environment: server.baseUrl });
        const rawRequestBody = {};
        const rawResponseBody = {
            nodes: [
                {
                    type: "conversation",
                    model: { provider: "openai", model: "gpt-4.1-2025-04-14" },
                    transcriber: {
                        provider: "assembly-ai",
                        confidenceThreshold: 0.4,
                        enableUniversalStreamingApi: false,
                        formatTurns: false,
                        endOfTurnConfidenceThreshold: 0.7,
                        minEndOfTurnSilenceWhenConfident: 160,
                        wordFinalizationMaxWaitTime: 160,
                        maxTurnSilence: 400,
                    },
                    voice: {
                        cachingEnabled: true,
                        provider: "azure",
                        voiceId: "andrew",
                        fallbackPlan: { voices: [{ cachingEnabled: true, provider: "azure", voiceId: "andrew" }] },
                    },
                    prompt: "prompt",
                    name: "name",
                    isStart: true,
                    metadata: { key: "value" },
                },
            ],
            transcriber: {
                provider: "assembly-ai",
                language: "en",
                confidenceThreshold: 0.4,
                enableUniversalStreamingApi: false,
                formatTurns: false,
                endOfTurnConfidenceThreshold: 0.7,
                minEndOfTurnSilenceWhenConfident: 160,
                wordFinalizationMaxWaitTime: 160,
                maxTurnSilence: 400,
                realtimeUrl: "realtimeUrl",
                wordBoost: ["wordBoost"],
                endUtteranceSilenceThreshold: 1.1,
                disablePartialTranscripts: true,
                fallbackPlan: {
                    transcribers: [
                        {
                            provider: "assembly-ai",
                            confidenceThreshold: 0.4,
                            enableUniversalStreamingApi: false,
                            formatTurns: false,
                            endOfTurnConfidenceThreshold: 0.7,
                            minEndOfTurnSilenceWhenConfident: 160,
                            wordFinalizationMaxWaitTime: 160,
                            maxTurnSilence: 400,
                        },
                    ],
                },
            },
            voice: {
                cachingEnabled: true,
                provider: "azure",
                voiceId: "andrew",
                chunkPlan: {
                    enabled: true,
                    minCharacters: 30,
                    punctuationBoundaries: ["。", "，", ".", "!", "?", ";", "،", "۔", "।", "॥", "|", "||", ",", ":"],
                    formatPlan: { enabled: true, numberToDigitsCutoff: 2025 },
                },
                speed: 1.1,
                fallbackPlan: { voices: [{ cachingEnabled: true, provider: "azure", voiceId: "andrew" }] },
            },
            observabilityPlan: { provider: "langfuse", tags: ["tags"], metadata: { key: "value" } },
            backgroundSound: "off",
            credentials: [{ provider: "11labs", apiKey: "apiKey", name: "name" }],
            id: "id",
            orgId: "orgId",
            createdAt: "2024-01-15T09:30:00Z",
            updatedAt: "2024-01-15T09:30:00Z",
            name: "name",
            edges: [
                { condition: { type: "ai", prompt: "prompt" }, from: "from", to: "to", metadata: { key: "value" } },
            ],
            globalPrompt: "globalPrompt",
            server: {
                timeoutSeconds: 20,
                url: "url",
                headers: { key: "value" },
                backoffPlan: { type: { key: "value" }, maxRetries: 0, baseDelaySeconds: 1 },
            },
            compliancePlan: { hipaaEnabled: true, pciEnabled: true },
            analysisPlan: {
                minMessagesThreshold: 1.1,
                summaryPlan: { messages: [{ key: "value" }], enabled: true, timeoutSeconds: 1.1 },
                structuredDataPlan: {
                    messages: [{ key: "value" }],
                    enabled: true,
                    schema: { type: "string" },
                    timeoutSeconds: 1.1,
                },
                structuredDataMultiPlan: [{ key: "key", plan: {} }],
                successEvaluationPlan: {
                    rubric: "NumericScale",
                    messages: [{ key: "value" }],
                    enabled: true,
                    timeoutSeconds: 1.1,
                },
            },
            artifactPlan: {
                recordingEnabled: true,
                recordingFormat: "wav;l16",
                videoRecordingEnabled: false,
                pcapEnabled: true,
                pcapS3PathPrefix: "/pcaps",
                transcriptPlan: { enabled: true, assistantName: "assistantName", userName: "userName" },
                recordingPath: "recordingPath",
            },
            startSpeakingPlan: {
                waitSeconds: 0.4,
                smartEndpointingPlan: { provider: "vapi" },
                customEndpointingRules: [{ type: "assistant", regex: "regex", timeoutSeconds: 1.1 }],
                transcriptionEndpointingPlan: {
                    onPunctuationSeconds: 0.1,
                    onNoPunctuationSeconds: 1.5,
                    onNumberSeconds: 0.5,
                },
            },
            stopSpeakingPlan: {
                numWords: 0,
                voiceSeconds: 0.2,
                backoffSeconds: 1,
                acknowledgementPhrases: [
                    "i understand",
                    "i see",
                    "i got it",
                    "i hear you",
                    "im listening",
                    "im with you",
                    "right",
                    "okay",
                    "ok",
                    "sure",
                    "alright",
                    "got it",
                    "understood",
                    "yeah",
                    "yes",
                    "uh-huh",
                    "mm-hmm",
                    "gotcha",
                    "mhmm",
                    "ah",
                    "yeah okay",
                    "yeah sure",
                ],
                interruptionPhrases: [
                    "stop",
                    "shut",
                    "up",
                    "enough",
                    "quiet",
                    "silence",
                    "but",
                    "dont",
                    "not",
                    "no",
                    "hold",
                    "wait",
                    "cut",
                    "pause",
                    "nope",
                    "nah",
                    "nevermind",
                    "never",
                    "bad",
                    "actually",
                ],
            },
            monitorPlan: {
                listenEnabled: false,
                listenAuthenticationEnabled: false,
                controlEnabled: false,
                controlAuthenticationEnabled: false,
            },
            backgroundSpeechDenoisingPlan: {
                smartDenoisingPlan: { enabled: true },
                fourierDenoisingPlan: {
                    enabled: true,
                    mediaDetectionEnabled: true,
                    staticThreshold: -35,
                    baselineOffsetDb: -15,
                    windowSizeMs: 3000,
                    baselinePercentile: 85,
                },
            },
            credentialIds: ["credentialIds"],
        };
        server
            .mockEndpoint()
            .patch("/workflow/id")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.workflow.workflowControllerUpdate("id");
        expect(response).toEqual({
            nodes: [
                {
                    type: "conversation",
                    model: {
                        provider: "openai",
                        model: "gpt-4.1-2025-04-14",
                    },
                    transcriber: {
                        provider: "assembly-ai",
                        confidenceThreshold: 0.4,
                        enableUniversalStreamingApi: false,
                        formatTurns: false,
                        endOfTurnConfidenceThreshold: 0.7,
                        minEndOfTurnSilenceWhenConfident: 160,
                        wordFinalizationMaxWaitTime: 160,
                        maxTurnSilence: 400,
                    },
                    voice: {
                        cachingEnabled: true,
                        provider: "azure",
                        voiceId: "andrew",
                        fallbackPlan: {
                            voices: [
                                {
                                    cachingEnabled: true,
                                    provider: "azure",
                                    voiceId: "andrew",
                                },
                            ],
                        },
                    },
                    prompt: "prompt",
                    name: "name",
                    isStart: true,
                    metadata: {
                        key: "value",
                    },
                },
            ],
            transcriber: {
                provider: "assembly-ai",
                language: "en",
                confidenceThreshold: 0.4,
                enableUniversalStreamingApi: false,
                formatTurns: false,
                endOfTurnConfidenceThreshold: 0.7,
                minEndOfTurnSilenceWhenConfident: 160,
                wordFinalizationMaxWaitTime: 160,
                maxTurnSilence: 400,
                realtimeUrl: "realtimeUrl",
                wordBoost: ["wordBoost"],
                endUtteranceSilenceThreshold: 1.1,
                disablePartialTranscripts: true,
                fallbackPlan: {
                    transcribers: [
                        {
                            provider: "assembly-ai",
                            confidenceThreshold: 0.4,
                            enableUniversalStreamingApi: false,
                            formatTurns: false,
                            endOfTurnConfidenceThreshold: 0.7,
                            minEndOfTurnSilenceWhenConfident: 160,
                            wordFinalizationMaxWaitTime: 160,
                            maxTurnSilence: 400,
                        },
                    ],
                },
            },
            voice: {
                cachingEnabled: true,
                provider: "azure",
                voiceId: "andrew",
                chunkPlan: {
                    enabled: true,
                    minCharacters: 30,
                    punctuationBoundaries: [
                        "\u3002",
                        "\uFF0C",
                        ".",
                        "!",
                        "?",
                        ";",
                        "\u060C",
                        "\u06D4",
                        "\u0964",
                        "\u0965",
                        "|",
                        "||",
                        ",",
                        ":",
                    ],
                    formatPlan: {
                        enabled: true,
                        numberToDigitsCutoff: 2025,
                    },
                },
                speed: 1.1,
                fallbackPlan: {
                    voices: [
                        {
                            cachingEnabled: true,
                            provider: "azure",
                            voiceId: "andrew",
                        },
                    ],
                },
            },
            observabilityPlan: {
                provider: "langfuse",
                tags: ["tags"],
                metadata: {
                    key: "value",
                },
            },
            backgroundSound: "off",
            credentials: [
                {
                    provider: "11labs",
                    apiKey: "apiKey",
                    name: "name",
                },
            ],
            id: "id",
            orgId: "orgId",
            createdAt: "2024-01-15T09:30:00Z",
            updatedAt: "2024-01-15T09:30:00Z",
            name: "name",
            edges: [
                {
                    condition: {
                        type: "ai",
                        prompt: "prompt",
                    },
                    from: "from",
                    to: "to",
                    metadata: {
                        key: "value",
                    },
                },
            ],
            globalPrompt: "globalPrompt",
            server: {
                timeoutSeconds: 20,
                url: "url",
                headers: {
                    key: "value",
                },
                backoffPlan: {
                    type: {
                        key: "value",
                    },
                    maxRetries: 0,
                    baseDelaySeconds: 1,
                },
            },
            compliancePlan: {
                hipaaEnabled: true,
                pciEnabled: true,
            },
            analysisPlan: {
                minMessagesThreshold: 1.1,
                summaryPlan: {
                    messages: [
                        {
                            key: "value",
                        },
                    ],
                    enabled: true,
                    timeoutSeconds: 1.1,
                },
                structuredDataPlan: {
                    messages: [
                        {
                            key: "value",
                        },
                    ],
                    enabled: true,
                    schema: {
                        type: "string",
                    },
                    timeoutSeconds: 1.1,
                },
                structuredDataMultiPlan: [
                    {
                        key: "key",
                        plan: {},
                    },
                ],
                successEvaluationPlan: {
                    rubric: "NumericScale",
                    messages: [
                        {
                            key: "value",
                        },
                    ],
                    enabled: true,
                    timeoutSeconds: 1.1,
                },
            },
            artifactPlan: {
                recordingEnabled: true,
                recordingFormat: "wav;l16",
                videoRecordingEnabled: false,
                pcapEnabled: true,
                pcapS3PathPrefix: "/pcaps",
                transcriptPlan: {
                    enabled: true,
                    assistantName: "assistantName",
                    userName: "userName",
                },
                recordingPath: "recordingPath",
            },
            startSpeakingPlan: {
                waitSeconds: 0.4,
                smartEndpointingPlan: {
                    provider: "vapi",
                },
                customEndpointingRules: [
                    {
                        type: "assistant",
                        regex: "regex",
                        timeoutSeconds: 1.1,
                    },
                ],
                transcriptionEndpointingPlan: {
                    onPunctuationSeconds: 0.1,
                    onNoPunctuationSeconds: 1.5,
                    onNumberSeconds: 0.5,
                },
            },
            stopSpeakingPlan: {
                numWords: 0,
                voiceSeconds: 0.2,
                backoffSeconds: 1,
                acknowledgementPhrases: [
                    "i understand",
                    "i see",
                    "i got it",
                    "i hear you",
                    "im listening",
                    "im with you",
                    "right",
                    "okay",
                    "ok",
                    "sure",
                    "alright",
                    "got it",
                    "understood",
                    "yeah",
                    "yes",
                    "uh-huh",
                    "mm-hmm",
                    "gotcha",
                    "mhmm",
                    "ah",
                    "yeah okay",
                    "yeah sure",
                ],
                interruptionPhrases: [
                    "stop",
                    "shut",
                    "up",
                    "enough",
                    "quiet",
                    "silence",
                    "but",
                    "dont",
                    "not",
                    "no",
                    "hold",
                    "wait",
                    "cut",
                    "pause",
                    "nope",
                    "nah",
                    "nevermind",
                    "never",
                    "bad",
                    "actually",
                ],
            },
            monitorPlan: {
                listenEnabled: false,
                listenAuthenticationEnabled: false,
                controlEnabled: false,
                controlAuthenticationEnabled: false,
            },
            backgroundSpeechDenoisingPlan: {
                smartDenoisingPlan: {
                    enabled: true,
                },
                fourierDenoisingPlan: {
                    enabled: true,
                    mediaDetectionEnabled: true,
                    staticThreshold: -35,
                    baselineOffsetDb: -15,
                    windowSizeMs: 3000,
                    baselinePercentile: 85,
                },
            },
            credentialIds: ["credentialIds"],
        });
    });
});
