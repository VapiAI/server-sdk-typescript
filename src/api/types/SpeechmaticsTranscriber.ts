/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as Vapi from "../index.js";

export interface SpeechmaticsTranscriber {
    /** This is the transcription provider that will be used. */
    provider: "speechmatics";
    /** This is the model that will be used for the transcription. */
    model?: "default";
    language?: SpeechmaticsTranscriber.Language;
    /**
     * This is the operating point for the transcription. Choose between `standard` for faster turnaround with strong accuracy or `enhanced` for highest accuracy when precision is critical.
     *
     * @default 'enhanced'
     */
    operatingPoint?: SpeechmaticsTranscriber.OperatingPoint;
    /**
     * This is the region for the Speechmatics API. Choose between EU (Europe) and US (United States) regions for lower latency and data sovereignty compliance.
     *
     * @default 'eu'
     */
    region?: SpeechmaticsTranscriber.Region;
    /**
     * This enables speaker diarization, which identifies and separates speakers in the transcription. Essential for multi-speaker conversations and conference calls.
     *
     * @default false
     */
    enableDiarization?: boolean;
    /**
     * This sets the maximum number of speakers to detect when diarization is enabled. Only used when enableDiarization is true.
     *
     * @default 2
     */
    maxSpeakers?: number;
    /**
     * This enables partial transcripts during speech recognition. When false, only final transcripts are returned.
     *
     * @default true
     */
    enablePartials?: boolean;
    /**
     * This sets the maximum delay in milliseconds for partial transcripts. Balances latency and accuracy.
     *
     * @default 3000
     */
    maxDelay?: number;
    customVocabulary: Vapi.SpeechmaticsCustomVocabularyItem[];
    /**
     * This controls how numbers are formatted in the transcription output.
     *
     * @default 'written'
     */
    numeralStyle?: SpeechmaticsTranscriber.NumeralStyle;
    /**
     * This enables detection of non-speech audio events like music, applause, and laughter.
     *
     * @default false
     */
    enableEntities?: boolean;
    /**
     * This enables automatic punctuation in the transcription output.
     *
     * @default true
     */
    enablePunctuation?: boolean;
    /**
     * This enables automatic capitalization in the transcription output.
     *
     * @default true
     */
    enableCapitalization?: boolean;
    /**
     * This is the sensitivity level for end-of-turn detection, which determines when a speaker has finished talking. Higher values are more sensitive.
     *
     * @default 0.5
     */
    endOfTurnSensitivity?: number;
    /**
     * This enables removal of disfluencies (um, uh) from the transcript to create cleaner, more professional output.
     *
     * @default false
     */
    removeDisfluencies?: boolean;
    /**
     * This is the minimum duration in seconds for speech segments. Shorter segments will be filtered out. Helps remove noise and improve accuracy.
     *
     * @default 0.0
     */
    minimumSpeechDuration?: number;
    /** This is the plan for voice provider fallbacks in the event that the primary voice provider fails. */
    fallbackPlan?: Vapi.FallbackTranscriberPlan;
}

export namespace SpeechmaticsTranscriber {
    export type Language =
        | "auto"
        | "ar"
        | "ba"
        | "eu"
        | "be"
        | "bn"
        | "bg"
        | "yue"
        | "ca"
        | "hr"
        | "cs"
        | "da"
        | "nl"
        | "en"
        | "eo"
        | "et"
        | "fi"
        | "fr"
        | "gl"
        | "de"
        | "el"
        | "he"
        | "hi"
        | "hu"
        | "id"
        | "ia"
        | "ga"
        | "it"
        | "ja"
        | "ko"
        | "lv"
        | "lt"
        | "ms"
        | "mt"
        | "cmn"
        | "mr"
        | "mn"
        | "no"
        | "fa"
        | "pl"
        | "pt"
        | "ro"
        | "ru"
        | "sk"
        | "sl"
        | "es"
        | "sw"
        | "sv"
        | "ta"
        | "th"
        | "tr"
        | "uk"
        | "ur"
        | "ug"
        | "vi"
        | "cy";
    export const Language = {
        Auto: "auto",
        Ar: "ar",
        Ba: "ba",
        Eu: "eu",
        Be: "be",
        Bn: "bn",
        Bg: "bg",
        Yue: "yue",
        Ca: "ca",
        Hr: "hr",
        Cs: "cs",
        Da: "da",
        Nl: "nl",
        En: "en",
        Eo: "eo",
        Et: "et",
        Fi: "fi",
        Fr: "fr",
        Gl: "gl",
        De: "de",
        El: "el",
        He: "he",
        Hi: "hi",
        Hu: "hu",
        Id: "id",
        Ia: "ia",
        Ga: "ga",
        It: "it",
        Ja: "ja",
        Ko: "ko",
        Lv: "lv",
        Lt: "lt",
        Ms: "ms",
        Mt: "mt",
        Cmn: "cmn",
        Mr: "mr",
        Mn: "mn",
        No: "no",
        Fa: "fa",
        Pl: "pl",
        Pt: "pt",
        Ro: "ro",
        Ru: "ru",
        Sk: "sk",
        Sl: "sl",
        Es: "es",
        Sw: "sw",
        Sv: "sv",
        Ta: "ta",
        Th: "th",
        Tr: "tr",
        Uk: "uk",
        Ur: "ur",
        Ug: "ug",
        Vi: "vi",
        Cy: "cy",
    } as const;
    /**
     * This is the operating point for the transcription. Choose between `standard` for faster turnaround with strong accuracy or `enhanced` for highest accuracy when precision is critical.
     *
     * @default 'enhanced'
     */
    export type OperatingPoint = "standard" | "enhanced";
    export const OperatingPoint = {
        Standard: "standard",
        Enhanced: "enhanced",
    } as const;
    /**
     * This is the region for the Speechmatics API. Choose between EU (Europe) and US (United States) regions for lower latency and data sovereignty compliance.
     *
     * @default 'eu'
     */
    export type Region = "eu" | "us";
    export const Region = {
        Eu: "eu",
        Us: "us",
    } as const;
    /**
     * This controls how numbers are formatted in the transcription output.
     *
     * @default 'written'
     */
    export type NumeralStyle = "written" | "spoken";
    export const NumeralStyle = {
        Written: "written",
        Spoken: "spoken",
    } as const;
}
