/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as Vapi from "../index.js";

export interface GroqModel {
    /** This is the starting state for the conversation. */
    messages?: Vapi.OpenAiMessage[];
    /**
     * These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.
     *
     * Both `tools` and `toolIds` can be used together.
     */
    tools?: GroqModel.Tools.Item[];
    /**
     * These are the tools that the assistant can use during the call. To use transient tools, use `tools`.
     *
     * Both `tools` and `toolIds` can be used together.
     */
    toolIds?: string[];
    /** These are the options for the knowledge base. */
    knowledgeBase?: Vapi.CreateCustomKnowledgeBaseDto;
    /** This is the ID of the knowledge base the model will use. */
    knowledgeBaseId?: string;
    /** This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b */
    model: GroqModel.Model;
    provider: "groq";
    /** This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency. */
    temperature?: number;
    /** This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250. */
    maxTokens?: number;
    /**
     * This determines whether we detect user's emotion while they speak and send it as an additional info to model.
     *
     * Default `false` because the model is usually are good at understanding the user's emotion from text.
     *
     * @default false
     */
    emotionRecognitionEnabled?: boolean;
    /**
     * This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.
     *
     * Default is 0.
     *
     * @default 0
     */
    numFastTurns?: number;
}

export namespace GroqModel {
    export type Tools = Tools.Item[];

    export namespace Tools {
        export type Item =
            | Vapi.CreateApiRequestToolDto
            | Vapi.CreateBashToolDto
            | Vapi.CreateComputerToolDto
            | Vapi.CreateDtmfToolDto
            | Vapi.CreateEndCallToolDto
            | Vapi.CreateFunctionToolDto
            | Vapi.CreateGoHighLevelCalendarAvailabilityToolDto
            | Vapi.CreateGoHighLevelCalendarEventCreateToolDto
            | Vapi.CreateGoHighLevelContactCreateToolDto
            | Vapi.CreateGoHighLevelContactGetToolDto
            | Vapi.CreateGoogleCalendarCheckAvailabilityToolDto
            | Vapi.CreateGoogleCalendarCreateEventToolDto
            | Vapi.CreateGoogleSheetsRowAppendToolDto
            | Vapi.CreateMcpToolDto
            | Vapi.CreateQueryToolDto
            | Vapi.CreateSlackSendMessageToolDto
            | Vapi.CreateSmsToolDto
            | Vapi.CreateTextEditorToolDto
            | Vapi.CreateTransferCallToolDto;
    }

    /**
     * This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
     */
    export type Model =
        | "deepseek-r1-distill-llama-70b"
        | "llama-3.3-70b-versatile"
        | "llama-3.1-405b-reasoning"
        | "llama-3.1-8b-instant"
        | "llama3-8b-8192"
        | "llama3-70b-8192"
        | "gemma2-9b-it"
        | "meta-llama/llama-4-maverick-17b-128e-instruct"
        | "meta-llama/llama-4-scout-17b-16e-instruct"
        | "mistral-saba-24b"
        | "compound-beta"
        | "compound-beta-mini";
    export const Model = {
        DeepseekR1DistillLlama70B: "deepseek-r1-distill-llama-70b",
        Llama3370BVersatile: "llama-3.3-70b-versatile",
        Llama31405BReasoning: "llama-3.1-405b-reasoning",
        Llama318BInstant: "llama-3.1-8b-instant",
        Llama38B8192: "llama3-8b-8192",
        Llama370B8192: "llama3-70b-8192",
        Gemma29BIt: "gemma2-9b-it",
        MetaLlamaLlama4Maverick17B128EInstruct: "meta-llama/llama-4-maverick-17b-128e-instruct",
        MetaLlamaLlama4Scout17B16EInstruct: "meta-llama/llama-4-scout-17b-16e-instruct",
        MistralSaba24B: "mistral-saba-24b",
        CompoundBeta: "compound-beta",
        CompoundBetaMini: "compound-beta-mini",
    } as const;
}
