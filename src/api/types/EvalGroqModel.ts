/**
 * This file was auto-generated by Fern from our API Definition.
 */

export interface EvalGroqModel {
    /** This is the provider of the model (`groq`). */
    provider: "groq";
    /** This is the name of the model. Ex. gpt-4o */
    model: EvalGroqModel.Model;
    /** This is the temperature of the model. For LLM-as-a-judge, it's recommended to set it between 0 - 0.3 to avoid hallucinations and ensure the model judges the output correctly based on the instructions. */
    temperature?: number;
    /**
     * This is the max tokens of the model.
     * If your Judge instructions return `true` or `false` takes only 1 token (as per the OpenAI Tokenizer), and therefore is recommended to set it to a low number to force the model to return a short response.
     */
    maxTokens?: number;
}

export namespace EvalGroqModel {
    /**
     * This is the name of the model. Ex. gpt-4o
     */
    export type Model =
        | "openai/gpt-oss-20b"
        | "openai/gpt-oss-120b"
        | "deepseek-r1-distill-llama-70b"
        | "llama-3.3-70b-versatile"
        | "llama-3.1-405b-reasoning"
        | "llama-3.1-8b-instant"
        | "llama3-8b-8192"
        | "llama3-70b-8192"
        | "gemma2-9b-it"
        | "moonshotai/kimi-k2-instruct-0905"
        | "meta-llama/llama-4-maverick-17b-128e-instruct"
        | "meta-llama/llama-4-scout-17b-16e-instruct"
        | "mistral-saba-24b"
        | "compound-beta"
        | "compound-beta-mini";
    export const Model = {
        OpenaiGptOss20B: "openai/gpt-oss-20b",
        OpenaiGptOss120B: "openai/gpt-oss-120b",
        DeepseekR1DistillLlama70B: "deepseek-r1-distill-llama-70b",
        Llama3370BVersatile: "llama-3.3-70b-versatile",
        Llama31405BReasoning: "llama-3.1-405b-reasoning",
        Llama318BInstant: "llama-3.1-8b-instant",
        Llama38B8192: "llama3-8b-8192",
        Llama370B8192: "llama3-70b-8192",
        Gemma29BIt: "gemma2-9b-it",
        MoonshotaiKimiK2Instruct0905: "moonshotai/kimi-k2-instruct-0905",
        MetaLlamaLlama4Maverick17B128EInstruct: "meta-llama/llama-4-maverick-17b-128e-instruct",
        MetaLlamaLlama4Scout17B16EInstruct: "meta-llama/llama-4-scout-17b-16e-instruct",
        MistralSaba24B: "mistral-saba-24b",
        CompoundBeta: "compound-beta",
        CompoundBetaMini: "compound-beta-mini",
    } as const;
}
